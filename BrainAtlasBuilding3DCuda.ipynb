{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "from lazy_imports import itkwidgets\n",
    "from lazy_imports import itkview\n",
    "from lazy_imports import interactive\n",
    "from lazy_imports import ipywidgets\n",
    "from lazy_imports import pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtch.RegistrationFunc3DCuda import *\n",
    "from mtch.SplitEbinMetric3DCuda import *\n",
    "from mtch.GeoPlot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Packages.disp.vis import show_2d, show_2d_tensors\n",
    "from disp.vis import vis_tensors, vis_path, disp_scalar_to_file\n",
    "from disp.vis import disp_vector_to_file, disp_tensor_to_file\n",
    "from disp.vis import disp_gradG_to_file, disp_gradA_to_file\n",
    "from disp.vis import view_3d_tensors, tensors_to_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import algo.metricModSolver2d as mms\n",
    "import algo.geodesic as geo\n",
    "import algo.euler as euler\n",
    "import algo.dijkstra as dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# after switch device, you need restart the script\n",
    "torch.cuda.set_device(1)\n",
    "torch.set_default_tensor_type('torch.cuda.DoubleTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data I/O convention\n",
    "\n",
    "### Read\n",
    "Shape of input_tensor.nhdr is `[d, w, h, 6]`, and Shape of input_mask.nhdr is `[d, w, h]`\n",
    "```\n",
    "input_tensor = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(path)),(3,2,1,0))\n",
    "input_mask = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(path)),(2,1,0))\n",
    "```\n",
    "input_tensor.shape is `[3, h, w, d]`, and input_mask.shape is `[h, w, d]`\n",
    "### Write\n",
    "output_tensor.shape is `[3, h, w, d]`, and output_mask.shape is `[h, w, d]`\n",
    "```\n",
    "output_tensor = sitk.WriteImage(sitk.GetImageFromArray(np.transpose(output_tensor,(3,2,1,0)), path)\n",
    "output_mask = sitk.WriteImage(sitk.GetImageFromArray(np.transpose(output_tensor,(2,1,0)), path)\n",
    "```\n",
    "Shape of output_tensor.nhdr is `[d, w, h, 3]`, and Shape of output_mask.nhdr is `[d, w, h]`\n",
    "\n",
    "### Note\n",
    "`sitk.WriteImage(sitk.GetImageFromArray())` and `sitk.GetArrayFromImage(sitk.ReadImage(path))` is a pair of inverse operation, and you can see there is no inconsistence with regards to the dimension issue.\n",
    "```\n",
    "output_tensor = np.zeros((12,34,56,78))\n",
    "sitk.WriteImage(sitk.GetImageFromArray(output_tensor), path)\n",
    "input_tensor = sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
    "print(input_tensor)\n",
    "'(12,34,56,78)'\n",
    "```\n",
    "\n",
    "## Data dim convention\n",
    "\n",
    "Make sure you follow the conventions below to make the algorithm consistent.\n",
    "- Tensor fields: All the tensor fields variables by default are of size `[h, w, d, 3, 3]`, making the last two dimensions index metric matrix, to comply pytorch. In my code, arguments and the outputs of all functions meet this requirement. \n",
    "- Compressed tensor fields: `atlas_lin` is always of size `[6, h, w, d]`, when it comes to the argument of `view_3d_tensors()`, using `np.transpose(atlas_lin,(1,2,3,0))` to satisfy the requirement temporarily.\n",
    "- Diffeomorphisms: All the diffeo variables by default are of size `[3, h, w, d]`.\n",
    "- Masks: All the mask variables by default are of size `[h, w, d]`, when it comes to `torch.einsum()`, you can use `.unsqueeze(0)` temporarily.\n",
    "\n",
    "## Data plotting convention\n",
    "\n",
    "To avoid the `x` and `y` ambiguity in indexing and ploting, naming the first two dimension in `[h, w, 2, 2]` in the order of `x`, `y` is the best choice! \n",
    "- When indexing the array, `x` indexes row and `y` indexes column, the way I typically do and the way how matplotlib plot the 2d image. \n",
    "- When plotting the tensors, matplotlib would rotate the array counterclockwise by 90 degrees. So the vertical axis is `y` and horizontal axis is `x`, which is also consistent with our knowledge in drawing the Cartesian coordinate system. Fortunately, Kirs' code has already done in this way, like the ellipse(x, y). \n",
    "\n",
    "\n",
    "## Algorithm caveat\n",
    "- In energy calculation, only use the binary mask provided by Kris, rather than a weighted map, which will change the alpha field applied to the tensor field previously and result in geodesic misgoing.\n",
    "- Both metric matching and mean calculating should be implemented on the inverse of the original DTI tensor field, since the geodesics are running on the inverse of the tensor field.\n",
    "- When accumulating the diffeomorphisms, always remember the order of accumulation of phi and its inverse is different.\n",
    "```\n",
    "phi_acc = compose_function(phi_acc, phi)\n",
    "psi_inv_acc = compose_function(phi_inv, psi_inv_acc)\n",
    "```\n",
    "- When an error like below is raised, it's probably caused by a large epsilon, so the composed tensor field is no longer positive definite everywhere.\n",
    "```\n",
    "cholesky_cpu: For batch 0: U(1,1) is zero, singular U.\n",
    "```\n",
    "- `a` in `Squared_distance_Ebin(g0, g1, a, mask)`, `get_karcher_mean(G, a)`, `get_geo(g0, g1, a, Tpts)`, `inv_RieExp_extended(g0, g1, a)`, `Rie_Exp_extended(g0, u, a)`, `Rie_Exp(g0, u, a)`, `inv_RieExp(g0, g1, a)` equals to the reciprocal of dimension, `1/dim`, namely the last entry of tensor field's shape.\n",
    "\n",
    "- When an out of range error is raised, check if all the tensors get the right dimension order.\n",
    "- Pay attention to the indexes when assigning the `atlas` to `atlas_lin`, there hasn't been any bugs in `SplitEbinMetric.py` found, to the best of my knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_pullback(phi, g):\n",
    "#     input: phi.shape = [3, h, w, d]; g.shape = [h, w, d, 3, 3]\n",
    "#     output: shape = [h, w, 2, 2]\n",
    "#     torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "    g = g.permute(3, 4, 0, 1, 2)\n",
    "    idty = get_idty(*g.shape[-3:])\n",
    "    #     four layers of scalar field, of all 1, all 0, all 1, all 0, where the shape of each layer is g.shape[-2:]?\n",
    "    eye = torch.eye(3)\n",
    "    ones = torch.ones(*g.shape[-3:])\n",
    "    d_phi = get_jacobian_matrix(phi - idty) + torch.einsum(\"ij,mno->ijmno\", eye, ones)\n",
    "    g_phi = compose_function(g, phi)\n",
    "    return torch.einsum(\"ij...,ik...,kl...->...jl\", d_phi, g_phi, d_phi)\n",
    "\n",
    "\n",
    "def energy_ebin(phi, g0, g1, f0, f1, sigma, dim, mask): \n",
    "#     input: phi.shape = [3, h, w, d]; g0/g1/f0/f1.shape = [h, w, d, 3, 3]; sigma/dim = scalar; mask.shape = [1, h, w, d]\n",
    "#     output: scalar\n",
    "# the phi here is identity\n",
    "    phi_star_g1 = phi_pullback(phi, g1)\n",
    "    phi_star_f1 = phi_pullback(phi, f1)# the compose operation in this step uses a couple of thousands MB of memory\n",
    "    E1 = sigma * Squared_distance_Ebin(f0, phi_star_f1, 1./dim, mask)\n",
    "    E2 = Squared_distance_Ebin(g0, phi_star_g1, 1./dim, mask)\n",
    "    return E1 + E2\n",
    "\n",
    "\n",
    "def energy_L2(phi, g0, g1, f0, f1, sigma, mask): \n",
    "#     input: phi.shape = [3, h, w, d]; g0/g1/f0/f1.shape = [h, w, d, 3, 3]; sigma = scalar; mask.shape = [1, h, w, d]\n",
    "#     output: scalar\n",
    "    phi_star_g1 = phi_pullback(phi, g1)\n",
    "    phi_star_f1 = phi_pullback(phi, f1)\n",
    "    E1 = sigma * torch.einsum(\"ijk...,lijk->\", (f0 - phi_star_f1) ** 2, mask.unsqueeze(0))\n",
    "    E2 = torch.einsum(\"ijk...,lijk->\", (g0 - phi_star_g1) ** 2, mask.unsqueeze(0))\n",
    "    # E = E1 + E2\n",
    "#     del phi_star_g1, phi_star_f1\n",
    "#     torch.cuda.empty_cache()\n",
    "    return E1 + E2\n",
    "\n",
    "\n",
    "def laplace_inverse(u):\n",
    "#     input: u.shape = [3, h, w, d]\n",
    "#     output: shape = [3, h, w, d]\n",
    "    '''\n",
    "    this function computes the laplacian inverse of a vector field u of size 3 x size_h x size_w x size_d\n",
    "    '''\n",
    "    size_h, size_w, size_d = u.shape[-3:]\n",
    "    idty = get_idty(size_h, size_w, size_d).cpu().numpy()\n",
    "    lap = 6. - 2. * (np.cos(2. * np.pi * idty[0] / size_h) +\n",
    "                     np.cos(2. * np.pi * idty[1] / size_w) +\n",
    "                     np.cos(2. * np.pi * idty[2] / size_d))\n",
    "    lap[0, 0] = 1.\n",
    "    lapinv = 1. / lap\n",
    "    lap[0, 0] = 0.\n",
    "    lapinv[0, 0] = 1.\n",
    "\n",
    "    u = u.cpu().detach().numpy()\n",
    "    fx = np.fft.fftn(u[0])\n",
    "    fy = np.fft.fftn(u[1])\n",
    "    fz = np.fft.fftn(u[2])\n",
    "    fx *= lapinv\n",
    "    fy *= lapinv\n",
    "    fz *= lapinv\n",
    "    vx = torch.from_numpy(np.real(np.fft.ifftn(fx)))\n",
    "    vy = torch.from_numpy(np.real(np.fft.ifftn(fy)))\n",
    "    vz = torch.from_numpy(np.real(np.fft.ifftn(fz)))\n",
    "\n",
    "    return torch.stack((vx, vy, vz)).to(device=torch.device('cuda'))\n",
    "\n",
    "        \n",
    "def metric_matching(gi, gm, height, width, depth, mask, iter_num, epsilon, sigma, dim):\n",
    "    phi_inv = get_idty(height, width, depth)\n",
    "    phi = get_idty(height, width, depth)\n",
    "    idty = get_idty(height, width, depth)\n",
    "    idty.requires_grad_()\n",
    "    f0 = torch.eye(int(dim)).repeat(height, width, depth, 1, 1)\n",
    "    f1 = torch.eye(int(dim)).repeat(height, width, depth, 1, 1)\n",
    "    \n",
    "    for j in range(iter_num):\n",
    "        phi_actsg0 = phi_pullback(phi_inv, gi)\n",
    "        phi_actsf0 = phi_pullback(phi_inv, f0)\n",
    "        E = energy_ebin(idty, phi_actsg0, gm, phi_actsf0, f1, sigma, dim, mask) \n",
    "        E.backward()\n",
    "        v = - laplace_inverse(idty.grad)\n",
    "        with torch.no_grad():\n",
    "            psi =  idty + epsilon*v  \n",
    "            psi[0][psi[0] > height - 1] = height - 1\n",
    "            psi[1][psi[1] > width - 1] = width - 1\n",
    "            psi[2][psi[2] > depth - 1] = depth - 1\n",
    "            psi[psi < 0] = 0\n",
    "            psi_inv =  idty - epsilon*v\n",
    "            psi_inv[0][psi_inv[0] > height - 1] = height - 1\n",
    "            psi_inv[1][psi_inv[1] > width - 1] = width - 1\n",
    "            psi_inv[2][psi_inv[2] > depth - 1] = depth - 1\n",
    "            psi_inv[psi_inv < 0] = 0\n",
    "            phi = compose_function(psi, phi)\n",
    "            phi_inv = compose_function(phi_inv, psi_inv)\n",
    "            idty.grad.data.zero_()\n",
    "            \n",
    "    gi = phi_pullback(phi_inv, gi)\n",
    "    return gi, phi, phi_inv\n",
    "\n",
    "\n",
    "def tensor_cleaning(g, scale_factor):\n",
    "#     det_zero_map = torch.where(torch.det(g)<=0,1.,0.)\n",
    "#     background = torch.einsum(\"mno,ij->mnoij\", torch.ones(*tensor_met_zeros.shape[:3]), torch.eye(3))*scale_factor\n",
    "#     g = g + torch.einsum('ijk...,lijk->ijk...', background, det_zero_map.unsqueeze(0))\n",
    "#     e,_ = torch.symeig(g)\n",
    "#     lambd1_neg_map = torch.where(e[:,:,:,0]<=0,1.,0.)\n",
    "#     lambd2_neg_map = torch.where(e[:,:,:,1]<=0,1.,0.)\n",
    "#     lambd3_neg_map = torch.where(e[:,:,:,2]<=0,1.,0.)\n",
    "#     abnormal_map = torch.where(lambd1_neg_map+lambd2_neg_map+lambd3_neg_map>0,1.,0.)\n",
    "    abnormal_map = torch.where(torch.det(g)>10,1.,0.)\n",
    "    background = torch.einsum(\"mno,ij->mnoij\", torch.ones(*tensor_met_zeros.shape[:3]), torch.eye(3))*scale_factor\n",
    "#     return torch.einsum('ijk...,lijk->ijk...', g, 1.-abnormal_map.unsqueeze(0))+\\\n",
    "#             torch.einsum('ijk...,lijk->ijk...', background, abnormal_map.unsqueeze(0))\n",
    "    return torch.einsum('ijk...,lijk->ijk...', g, 1.-abnormal_map.unsqueeze(0))+\\\n",
    "            torch.einsum('ijk...,lijk->ijk...', g, (abnormal_map/torch.det(g)).unsqueeze(0))\n",
    "\n",
    "    \n",
    "def fractional_anisotropy(g):\n",
    "    e, _ = torch.symeig(g)\n",
    "    lambd1 = e[:,:,:,0]\n",
    "    lambd2 = e[:,:,:,1]\n",
    "    lambd3 = e[:,:,:,2]\n",
    "    mean = torch.mean(e,dim=len(e.shape)-1)\n",
    "    return torch.sqrt(3.*(torch.pow((lambd1-mean),2)+torch.pow((lambd2-mean),2)+torch.pow((lambd3-mean),2)))/\\\n",
    "    torch.sqrt(2.*(torch.pow(lambd1,2)+torch.pow(lambd2,2)+torch.pow(lambd3,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from iteration 0 to iteration 800\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "# plt.imshow(torch.det(tensor_met_list[0])[:,:,20])\n",
    "start_iter = 0\n",
    "iter_num = 800\n",
    "print(f'Starting from iteration {start_iter} to iteration {iter_num+start_iter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exception thrown in SimpleITK ImageFileReader_Execute: /tmp/SimpleITK/Code/IO/src/sitkImageReaderBase.cxx:97:\nsitk::ERROR: The file \"/usr/sci/projects/HCP/Kris/NSFCRCNS/TestResults/UKF_experiments/108222_scaled_tensors.nhdr\" does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bbcb587fd34e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# for s in range(1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     read tensor and mask files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtensor_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{input_dir}/{file_name[s]}_scaled_tensors.nhdr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmask_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{input_dir}/{file_name[s]}_filt_mask.nhdr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtensor_lin_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python37/lib/python3.7/site-packages/SimpleITK/extra.py\u001b[0m in \u001b[0;36mReadImage\u001b[0;34m(fileName, outputPixelType, imageIO)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetImageIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageIO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputPixelType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPixelType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python37/lib/python3.7/site-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36mExecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5777\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5778\u001b[0m         \u001b[0;34mr\"\"\"Execute(ImageFileReader self) -> Image\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5779\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFileReader_Execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mReadImageInformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception thrown in SimpleITK ImageFileReader_Execute: /tmp/SimpleITK/Code/IO/src/sitkImageReaderBase.cxx:97:\nsitk::ERROR: The file \"/usr/sci/projects/HCP/Kris/NSFCRCNS/TestResults/UKF_experiments/108222_scaled_tensors.nhdr\" does not exist."
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "file_name = [108222, 102715, 105923]\n",
    "input_dir = '/usr/sci/projects/HCP/Kris/NSFCRCNS/TestResults/UKF_experiments'\n",
    "output_dir = 'BrainAtlasUkf1Cuda'\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "height, width, depth = 145,174,145\n",
    "sample_num = len(file_name)\n",
    "tensor_lin_list, tensor_met_list, mask_list, mask_thresh_list, fa_list = [], [], [], [], []\n",
    "mask_union = torch.zeros(height, width, depth).double().to(device)\n",
    "phi_inv_acc_list, phi_acc_list, energy_list = [], [], []\n",
    "resume = False\n",
    "\n",
    "for s in range(len(file_name)):\n",
    "# for s in range(1):\n",
    "#     read tensor and mask files\n",
    "    tensor_np = sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/{file_name[s]}_scaled_tensors.nhdr'))\n",
    "    mask_np = sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/{file_name[s]}_filt_mask.nhdr'))\n",
    "    tensor_lin_list.append(torch.from_numpy(tensor_np).double().permute(3,2,1,0).to(device))\n",
    "#     create union of masks\n",
    "#     print(torch.from_numpy(mask_np).double().permute(2,1,0).to(device).is_cuda)\n",
    "    mask_union += torch.from_numpy(mask_np).double().permute(2,1,0).to(device)\n",
    "    mask_list.append(torch.from_numpy(mask_np).double().permute(2,1,0))\n",
    "#     rearrange tensor_lin to tensor_met\n",
    "    tensor_met_zeros = torch.zeros(height,width,depth,3,3,dtype=torch.float64)\n",
    "    tensor_met_zeros[:,:,:,0,0] = tensor_lin_list[s][0]\n",
    "    tensor_met_zeros[:,:,:,0,1] = tensor_lin_list[s][1]\n",
    "    tensor_met_zeros[:,:,:,0,2] = tensor_lin_list[s][2]\n",
    "    tensor_met_zeros[:,:,:,1,0] = tensor_lin_list[s][1]\n",
    "    tensor_met_zeros[:,:,:,1,1] = tensor_lin_list[s][3]\n",
    "    tensor_met_zeros[:,:,:,1,2] = tensor_lin_list[s][4]\n",
    "    tensor_met_zeros[:,:,:,2,0] = tensor_lin_list[s][2]\n",
    "    tensor_met_zeros[:,:,:,2,1] = tensor_lin_list[s][4]\n",
    "    tensor_met_zeros[:,:,:,2,2] = tensor_lin_list[s][5]\n",
    "#     balance the background and subject by rescaling\n",
    "#     tensor_met_zeros = tensor_cleaning(tensor_met_zeros, scale_factor=torch.tensor(1,dtype=torch.float64))\n",
    "    fa_list.append(fractional_anisotropy(tensor_met_zeros))\n",
    "    tensor_met_list.append(torch.inverse(tensor_met_zeros))\n",
    "    fore_back_adaptor = torch.where(torch.det(tensor_met_list[s])>1e2, 1e-3, 1.)\n",
    "    mask_thresh_list.append(fore_back_adaptor)\n",
    "    tensor_met_list[s] = torch.einsum('ijk...,lijk->ijk...', tensor_met_list[s], mask_thresh_list[s].unsqueeze(0))\n",
    "#     initialize the accumulative diffeomorphism    \n",
    "    if resume==False:\n",
    "        print('start from identity')\n",
    "        phi_inv_acc_list.append(get_idty(height, width, depth))\n",
    "        phi_acc_list.append(get_idty(height, width, depth))\n",
    "    else:\n",
    "        print('start from checkpoint')\n",
    "        phi_inv_acc_list.append(torch.from_numpy(sio.loadmat(f'{output_dir}/brain{file_name[s]}_{start_iter-1}_phi_inv.mat')['diffeo']))\n",
    "        phi_acc_list.append(torch.from_numpy(sio.loadmat(f'{output_dir}/brain{file_name[s]}_{start_iter-1}_phi.mat')['diffeo']))\n",
    "        tensor_met_list[s] = phi_pullback(phi_inv_acc_list[s], tensor_met_list[s])\n",
    "    energy_list.append([])    \n",
    "    \n",
    "mask_union[mask_union>0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inverse_cpu: For batch 0: U(1,1) is zero, singular U.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8c259a0d9815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_met_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num_matching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# epsilon = 3e-3 for orig tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0matlas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_karcher_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mphi_inv_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Atlas3D/mtch/SplitEbinMetric3DCuda.py\u001b[0m in \u001b[0;36mget_karcher_mean\u001b[0;34m(G, a)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;31m#         print('logm_invB_A')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogm_invB_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         UTrless = U - torch.einsum(\"...ii,kl->...kl\", U, torch.eye(size[-1], dtype=torch.double)) / size[\n\u001b[1;32m    273\u001b[0m             -1]  # (...,2,2)\n",
      "\u001b[0;32m~/Projects/Atlas3D/mtch/SplitEbinMetric3DCuda.py\u001b[0m in \u001b[0;36mlogm_invB_A\u001b[0;34m(B, A)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mlog_lamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'...ji,...jk->...ik'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0minv_V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'...ij,...jk,...kl->...il'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_lamda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_V\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inverse_cpu: For batch 0: U(1,1) is zero, singular U."
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(start_iter, start_iter+iter_num)):\n",
    "    G = torch.stack(tuple(tensor_met_list))\n",
    "    dim, sigma, epsilon, iter_num_matching = 3., 0, 5e-3, 1 # epsilon = 3e-3 for orig tensor\n",
    "    atlas = get_karcher_mean(G, 1./dim)\n",
    "\n",
    "    phi_inv_list, phi_list = [], []\n",
    "    for s in range(sample_num):\n",
    "        energy_list[s].append(torch.einsum(\"ijk...,lijk->\",[(tensor_met_list[s] - atlas)**2, mask_union.unsqueeze(0)]).item())\n",
    "        old = tensor_met_list[s]\n",
    "        tensor_met_list[s], phi, phi_inv = metric_matching(tensor_met_list[s], atlas, height, width, depth, mask_union, iter_num_matching, epsilon, sigma,dim)\n",
    "        phi_inv_list.append(phi_inv)\n",
    "        phi_list.append(phi)\n",
    "        phi_inv_acc_list[s] = compose_function(phi_inv_acc_list[s], phi_inv_list[s])\n",
    "        phi_acc_list[s] = compose_function(phi_list[s], phi_acc_list[s])\n",
    "        mask_list[s] = compose_function(mask_list[s], phi_inv_list[s])\n",
    "#         if i%1==0:\n",
    "#             plot_diffeo(phi_acc_list[s][1:, 50, :, :], step_size=2, show_axis=True)\n",
    "#             plot_diffeo(phi_acc_list[s][:2, :, :, 20], step_size=2, show_axis=True)\n",
    "#             plot_diffeo(torch.stack((phi_acc_list[s][0, :, 50, :],phi_acc_list[s][2, :, 50, :]),0), step_size=2, show_axis=True)\n",
    "            \n",
    "    '''check point'''\n",
    "    if i%25==0:\n",
    "        atlas_lin = np.zeros((6,height,width,depth))\n",
    "        mask_acc = np.zeros((height,width,depth))\n",
    "        atlas_inv = torch.inverse(atlas)\n",
    "        atlas_lin[0] = atlas_inv[:,:,:,0,0].cpu()\n",
    "        atlas_lin[1] = atlas_inv[:,:,:,0,1].cpu()\n",
    "        atlas_lin[2] = atlas_inv[:,:,:,0,2].cpu()\n",
    "        atlas_lin[3] = atlas_inv[:,:,:,1,1].cpu()\n",
    "        atlas_lin[4] = atlas_inv[:,:,:,1,2].cpu()\n",
    "        atlas_lin[5] = atlas_inv[:,:,:,2,2].cpu()\n",
    "        for s in range(sample_num):\n",
    "            sio.savemat(f'{output_dir}/{file_name[s]}_{i}_phi_inv.mat', {'diffeo': phi_inv_acc_list[s].cpu().detach().numpy()})\n",
    "            sio.savemat(f'{output_dir}/{file_name[s]}_{i}_phi.mat', {'diffeo': phi_acc_list[s].cpu().detach().numpy()})\n",
    "            sio.savemat(f'{output_dir}/{file_name[s]}_{i}_energy.mat', {'energy': energy_list[s]})\n",
    "#             plt.plot(energy_list[s])\n",
    "            mask_acc += mask_list[s].cpu().numpy()\n",
    "        mask_acc[mask_acc>0]=1\n",
    "        sitk.WriteImage(sitk.GetImageFromArray(np.transpose(atlas_lin,(3,2,1,0))), f'{output_dir}/atlas_{i}_tens.nhdr')\n",
    "        sitk.WriteImage(sitk.GetImageFromArray(np.transpose(mask_union,(2,1,0))), f'{output_dir}/atlas_{i}_mask.nhdr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "atlas_lin = np.zeros((6,height,width,depth))\n",
    "mask_acc = np.zeros((height,width,depth))\n",
    "\n",
    "for s in range(sample_num):\n",
    "    sio.savemat(f'{output_dir}/brain{file_name[s]}_phi_inv.mat', {'diffeo': phi_inv_acc_list[s].cpu().detach().numpy()})\n",
    "    sio.savemat(f'{output_dir}/brain{file_name[s]}_phi.mat', {'diffeo': phi_acc_list[s].cpu().detach().numpy()})\n",
    "    sio.savemat(f'{output_dir}/brain{file_name[s]}_energy.mat', {'energy': energy_list[s]})\n",
    "    \n",
    "    plt.plot(energy_list[s])\n",
    "    mask_acc += mask_list[s].cpu().numpy()\n",
    "\n",
    "atlas = torch.inverse(atlas)\n",
    "atlas_lin[0] = atlas[:,:,:,0,0].cpu()\n",
    "atlas_lin[1] = atlas[:,:,:,0,1].cpu()\n",
    "atlas_lin[2] = atlas[:,:,:,0,2].cpu()\n",
    "atlas_lin[3] = atlas[:,:,:,1,1].cpu()\n",
    "atlas_lin[4] = atlas[:,:,:,1,2].cpu()\n",
    "atlas_lin[5] = atlas[:,:,:,2,2].cpu()\n",
    "mask_acc[mask_acc>0]=1\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.transpose(atlas_lin,(3,2,1,0))), f'{output_dir}/atlas_tens.nhdr')\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.transpose(mask_union,(2,1,0))), f'{output_dir}/atlas_mask.nhdr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_acc = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{output_dir}/atlas_mask.nhdr')),(2,1,0))\n",
    "atlas_lin = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{output_dir}/atlas_tens.nhdr')),(3,2,1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diffeomorphism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_3d_diffeos(diffeo, stride, interp):\n",
    "    height, width, depth = diffeo.shape[1:]\n",
    "    spline = []\n",
    "    for i in range(1,height,stride):\n",
    "        for j in range(1,width,stride):\n",
    "            spline.append(pv.Spline(np.transpose(diffeo[:,i,j,:]), interp))\n",
    "            \n",
    "    for i in range(1,height,stride):\n",
    "        for k in range(1,depth,stride):\n",
    "            spline.append(pv.Spline(np.transpose(diffeo[:,i,:,k]), interp))\n",
    "            \n",
    "    for j in range(1,width,stride):\n",
    "        for k in range(1,depth,stride):\n",
    "            spline.append(pv.Spline(np.transpose(diffeo[:,:,j,k]), interp))\n",
    "            \n",
    "    return itkview(geometries=spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e87828677c14dd3ba45aa62e3d2493b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberOâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# diffeo = sio.loadmat(f'{output_dir}/105923_799_phi_inv.mat')['diffeo']\n",
    "diffeo = sio.loadmat(f'/home/sci/hdai/Projects/Atlas3D/output/BrainAtlasUkfBallMetSept11/105923_800_phi_inv.mat')['diffeo']\n",
    "vwr = view_3d_diffeos(diffeo, 5,1000)\n",
    "vwr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `geo.geodesicpath`'s input tensor should be original DTI tensor field, instead of the inverted one. So make sure save the DTI like result, rather than inverted atlas.\n",
    "- If you are want to visualize the path by itkview, it's recommended that **set the `both_directions` argument as `False`**. As the itkview will connect all the points in order, not like plotting the points densely in 2D case. The `geo.geodesicpath_3d` returns a concatenated list of both directions but without reversing one of them, therefore the list returned by the function is actually not in order.\n",
    "    - Likewise, setting the `geo_iters` large is better than small, as the logic in `geo.geodesicpath_3d` is like: if the expected path doesn't go beyond the mask region, the last element in the returned list would be `[0,0,0]`, which leads to a twist path after calling the `view_3d_tensors`, due to the property of `pyvista.spline`; if the expected path goes beyond the mask region, the algorithm would be forced to suspend, and the last element in the returned list wouldn't be `[0,0,0]`.\n",
    "- At `[13, 14, 21]`, the four cubics and atlas are approximately overlapped, as for the other position, this is not guaranteed.\n",
    "- When calling the `geo.geodesicpath_3d`, **make sure the mask you put in `mask_image`(second) argument aligns with the object as accurate as possible**. The `mask_union`, which covers unnecessary area, will result in the extremely slow running in `util.diff.gradient_mask_3d` and `util.maskops.determine_boundary_3d`. But in visualization, using `mask_union` is acceptable.\n",
    "- To distinguish each path, you can use the drop-down menu locates at the down-left corner of the interactive window, switch to the geometry you would like to change and choose a color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geodesic on atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_set = []\n",
    "start_coords = [[13, 14, 21]]\n",
    "init_velocities = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwr=view_3d_tensors(np.transpose(atlas_lin,(1,2,3,0)),mask_acc,atlas_lin[3,:,:,:],paths=[],stride=6,scale=6)\n",
    "vwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "geo_delta_t = -0.1\n",
    "geo_iters = 1200 \n",
    "euler_delta_t = 0.1\n",
    "euler_iters = 8000 \n",
    "\n",
    "# geodesicpath_3d([6,h,w,d],[h,w,d],...)\n",
    "geox, geoy, geoz = geo.geodesicpath_3d(atlas_lin, mask_union,\\\n",
    "                              start_coords[0], init_velocities[0], \\\n",
    "                              geo_delta_t, iter_num=geo_iters, both_directions=False)\n",
    "\n",
    "# eulerpath_3d([6,h,w,d],[h,w,d],...)\n",
    "# eulx, euly, eulz = euler.eulerpath_3d(atlas_lin, mask_union,\\\n",
    "#                               start_coords[0], init_velocities[0], euler_delta_t, iter_num=euler_iters, both_directions=False)\n",
    "path_set = [(geox[:-1], geoy[:-1], geoz[:-1])]\n",
    "\n",
    "# view_3d_tensors([h,w,d,6],[h,w,d],...)\n",
    "vwr=view_3d_tensors(np.transpose(atlas_lin,(1,2,3,0)),mask_acc,atlas_lin[3,:,:,:],paths=path_set,stride=6,scale=6)\n",
    "vwr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geodesics on atlas and cubics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_delta_t = 0.1\n",
    "geo_iters = 1200 \n",
    "\n",
    "for s in file_name:\n",
    "    tensor_lin = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/{file_name[s]}/scaled_tensors.nhdr')),(3,2,1,0))\n",
    "    mask = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/{file_name[s]}/filt_mask.nhdr')),(2,1,0))\n",
    "    geox, geoy, geoz = geo.geodesicpath_3d(tensor_lin, mask,\\\n",
    "                                            start_coords[0], init_velocities[0], \\\n",
    "                                            geo_delta_t, iter_num=geo_iters, both_directions=False)\n",
    "    path_set.append((geox[:-1],geoy[:-1],geoz[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwr=view_3d_tensors(np.transpose(atlas_lin,(1,2,3,0)),mask_union,atlas_lin[3,:,:,:],paths=path_set,stride=6,scale=6)\n",
    "vwr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geodesics on cubics pushforwarded to the atlas space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def coord_register(point_x, point_y, point_z, diffeo):\n",
    "  # TODO work out which is y and which is x, maintain consistency.\n",
    "  # For now, pass in y for point_x, x for point_y\n",
    "    height, width, depth=diffeo.shape[-3:]\n",
    "    new_point_x, new_point_y, new_point_z = [], [], []\n",
    "    for i in range(len(point_x)):\n",
    "        C = point_x[i] - math.floor(point_x[i])\n",
    "        D = point_y[i] - math.floor(point_y[i])\n",
    "        E = point_z[i] - math.floor(point_z[i])\n",
    "        new_point_x.append(\\\n",
    "          (1.-C)*(1.-D)*(1.-E)*diffeo[0, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*(1.-E)*diffeo[0, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*(1.-E)*diffeo[0, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*D*(1.-E)*diffeo[0, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*(1.-D)*E*diffeo[0, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*E*diffeo[0, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*E*diffeo[0, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*D*E*diffeo[0, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth])\n",
    "\n",
    "        new_point_y.append(\\\n",
    "          (1.-C)*(1.-D)*(1.-E)*diffeo[1, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*(1.-E)*diffeo[1, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*(1.-E)*diffeo[1, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*D*(1.-E)*diffeo[1, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*(1.-D)*E*diffeo[1, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*E*diffeo[1, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*E*diffeo[1, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*D*E*diffeo[1, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth])\n",
    "\n",
    "        new_point_z.append(\\\n",
    "          (1.-C)*(1.-D)*(1.-E)*diffeo[2, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*(1.-E)*diffeo[2, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*(1.-E)*diffeo[2, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*D*(1.-E)*diffeo[2, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*(1.-D)*E*diffeo[2, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*E*diffeo[2, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*E*diffeo[2, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*D*E*diffeo[2, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth])\n",
    " \n",
    "    return (new_point_x, new_point_y, new_point_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_set = []\n",
    "start_coords = [[13, 14, 21]] # golden test start point\n",
    "init_velocities = [None]\n",
    "geo_delta_t = 0.1\n",
    "geo_iters = 1300 \n",
    "\n",
    "for s in file_name:\n",
    "    tensor_lin = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/{file_name[s]}/scaled_tensors.nhdr')),(3,2,1,0))\n",
    "    mask = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/{file_name[s]}/filt_mask.nhdr')),(2,1,0))\n",
    "    diffeo = sio.loadmat(f'{output_dir}/{file_name[s]}_799_phi.mat')['diffeo']\n",
    "    geox, geoy, geoz = geo.geodesicpath_3d(tensor_lin, mask,\\\n",
    "                                            start_coords[0], init_velocities[0], \\\n",
    "                                            geo_delta_t, iter_num=geo_iters, both_directions=False)\n",
    "    path_set.append(coord_register(geox[:-1], geoy[:-1], geoz[:-1], diffeo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwr=view_3d_tensors(np.transpose(atlas_lin,(1,2,3,0)),mask_acc,atlas_lin[3,:,:,:],paths=path_set,stride=6,scale=6)\n",
    "vwr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
