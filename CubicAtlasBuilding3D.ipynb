{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from lazy_imports import itkwidgets\n",
    "from lazy_imports import itkview\n",
    "from lazy_imports import interactive\n",
    "from lazy_imports import ipywidgets\n",
    "from lazy_imports import pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtch.RegistrationFunc3D import *\n",
    "from mtch.SplitEbinMetric3D import *\n",
    "from mtch.GeoPlot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Packages.disp.vis import show_2d, show_2d_tensors\n",
    "from disp.vis import vis_tensors, vis_path, disp_scalar_to_file\n",
    "from disp.vis import disp_vector_to_file, disp_tensor_to_file\n",
    "from disp.vis import disp_gradG_to_file, disp_gradA_to_file\n",
    "from disp.vis import view_3d_tensors, tensors_to_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import algo.metricModSolver2d as mms\n",
    "import algo.geodesic as geo\n",
    "import algo.euler as euler\n",
    "import algo.dijkstra as dijkstra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data I/O convention\n",
    "\n",
    "### Read\n",
    "Shape of input_tensor.nhdr is `[d, w, h, 6]`, and Shape of input_mask.nhdr is `[d, w, h]`\n",
    "```\n",
    "input_tensor = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(path)),(3,2,1,0))\n",
    "input_mask = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(path)),(2,1,0))\n",
    "```\n",
    "input_tensor.shape is `[3, h, w, d]`, and input_mask.shape is `[h, w, d]`\n",
    "### Write\n",
    "output_tensor.shape is `[3, h, w, d]`, and output_mask.shape is `[h, w, d]`\n",
    "```\n",
    "output_tensor = sitk.WriteImage(sitk.GetImageFromArray(np.transpose(output_tensor,(3,2,1,0)), path)\n",
    "output_mask = sitk.WriteImage(sitk.GetImageFromArray(np.transpose(output_tensor,(2,1,0)), path)\n",
    "```\n",
    "Shape of output_tensor.nhdr is `[d, w, h, 3]`, and Shape of output_mask.nhdr is `[d, w, h]`\n",
    "\n",
    "### Note\n",
    "`sitk.WriteImage(sitk.GetImageFromArray())` and `sitk.GetArrayFromImage(sitk.ReadImage(path))` is a pair of inverse operation, and you can see there is no inconsistence with regards to the dimension issue.\n",
    "```\n",
    "output_tensor = np.zeros((12,34,56,78))\n",
    "sitk.WriteImage(sitk.GetImageFromArray(output_tensor), path)\n",
    "input_tensor = sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
    "print(input_tensor)\n",
    "'(12,34,56,78)'\n",
    "```\n",
    "\n",
    "## Data dim convention\n",
    "\n",
    "Make sure you follow the conventions below to make the algorithm consistent.\n",
    "- Tensor fields: All the tensor fields variables by default are of size `[h, w, d, 3, 3]`, making the last two dimensions index metric matrix, to comply pytorch. In my code, arguments and the outputs of all functions meet this requirement. \n",
    "- Compressed tensor fields: `atlas_lin` is always of size `[6, h, w, d]`, when it comes to the argument of `view_3d_tensors()`, using `np.transpose(atlas_lin,(1,2,3,0))` to satisfy the requirement temporarily.\n",
    "- Diffeomorphisms: All the diffeo variables by default are of size `[3, h, w, d]`.\n",
    "- Masks: All the mask variables by default are of size `[h, w, d]`, when it comes to `torch.einsum()`, you can use `.unsqueeze(0)` temporarily.\n",
    "\n",
    "## Data plotting convention\n",
    "\n",
    "To avoid the `x` and `y` ambiguity in indexing and ploting, naming the first two dimension in `[h, w, 2, 2]` in the order of `x`, `y` is the best choice! \n",
    "- When indexing the array, `x` indexes row and `y` indexes column, the way I typically do and the way how matplotlib plot the 2d image. \n",
    "- When plotting the tensors, matplotlib would rotate the array counterclockwise by 90 degrees. So the vertical axis is `y` and horizontal axis is `x`, which is also consistent with our knowledge in drawing the Cartesian coordinate system. Fortunately, Kirs' code has already done in this way, like the ellipse(x, y). \n",
    "\n",
    "\n",
    "## Algorithm caveat\n",
    "- In energy calculation, only use the binary mask provided by Kris, rather than a weighted map, which will change the alpha field applied to the tensor field previously and result in geodesic misgoing.\n",
    "- Both metric matching and mean calculating should be implemented on the inverse of the original DTI tensor field, since the geodesics are running on the inverse of the tensor field.\n",
    "- When accumulating the diffeomorphisms, always remember the order of accumulation of phi and its inverse is different.\n",
    "```\n",
    "phi_acc = compose_function(phi_acc, phi)\n",
    "psi_inv_acc = compose_function(phi_inv, psi_inv_acc)\n",
    "```\n",
    "- When an error like below is raised, it's probably caused by a large epsilon, so the composed tensor field is no longer positive definite everywhere.\n",
    "```\n",
    "cholesky_cpu: For batch 0: U(1,1) is zero, singular U.\n",
    "```\n",
    "- `a` in `Squared_distance_Ebin(g0, g1, a, mask)`, `get_karcher_mean(G, a)`, `get_geo(g0, g1, a, Tpts)`, `inv_RieExp_extended(g0, g1, a)`, `Rie_Exp_extended(g0, u, a)`, `Rie_Exp(g0, u, a)`, `inv_RieExp(g0, g1, a)` equals to the reciprocal of dimension, `1/dim`, namely the last entry of tensor field's shape.\n",
    "\n",
    "- When an out of range error is raised, check if all the tensors get the right dimension order.\n",
    "- Pay attention to the indexes when assigning the `atlas` to `atlas_lin`, there hasn't been any bugs in `SplitEbinMetric.py` found, to the best of my knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_pullback(phi, g):\n",
    "#     input: phi.shape = [3, h, w, d]; g.shape = [h, w, d, 3, 3]\n",
    "#     output: shape = [h, w, 2, 2]\n",
    "#     torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "    g = g.permute(3, 4, 0, 1, 2)\n",
    "    idty = get_idty(*g.shape[-3:])\n",
    "    #     four layers of scalar field, of all 1, all 0, all 1, all 0, where the shape of each layer is g.shape[-2:]?\n",
    "    eye = torch.eye(3)\n",
    "    ones = torch.ones(*g.shape[-3:])\n",
    "    d_phi = get_jacobian_matrix(phi - idty) + torch.einsum(\"ij,mno->ijmno\", eye, ones)\n",
    "    g_phi = compose_function(g, phi)\n",
    "    return torch.einsum(\"ij...,ik...,kl...->...jl\", d_phi, g_phi, d_phi)\n",
    "\n",
    "\n",
    "def energy_ebin(phi, g0, g1, f0, f1, sigma, dim, mask): \n",
    "#     input: phi.shape = [3, h, w, d]; g0/g1/f0/f1.shape = [h, w, d, 3, 3]; sigma/dim = scalar; mask.shape = [1, h, w, d]\n",
    "#     output: scalar\n",
    "# the phi here is identity\n",
    "    phi_star_g1 = phi_pullback(phi, g1)\n",
    "    phi_star_f1 = phi_pullback(phi, f1)# the compose operation in this step uses a couple of thousands MB of memory\n",
    "    E1 = sigma * Squared_distance_Ebin(f0, phi_star_f1, 1./dim, mask)\n",
    "    E2 = Squared_distance_Ebin(g0, phi_star_g1, 1./dim, mask)\n",
    "    return E1 + E2\n",
    "\n",
    "\n",
    "\n",
    "def energy_L2(phi, g0, g1, f0, f1, sigma, mask): \n",
    "#     input: phi.shape = [3, h, w, d]; g0/g1/f0/f1.shape = [h, w, d, 3, 3]; sigma = scalar; mask.shape = [1, h, w, d]\n",
    "#     output: scalar\n",
    "    phi_star_g1 = phi_pullback(phi, g1)\n",
    "    phi_star_f1 = phi_pullback(phi, f1)\n",
    "    E1 = sigma * torch.einsum(\"ijk...,lijk->\", (f0 - phi_star_f1) ** 2, mask.unsqueeze(0))\n",
    "    E2 = torch.einsum(\"ijk...,lijk->\", (g0 - phi_star_g1) ** 2, mask.unsqueeze(0))\n",
    "    # E = E1 + E2\n",
    "#     del phi_star_g1, phi_star_f1\n",
    "#     torch.cuda.empty_cache()\n",
    "    return E1 + E2\n",
    "\n",
    "\n",
    "def laplace_inverse(u):\n",
    "#     input: u.shape = [3, h, w, d]\n",
    "#     output: shape = [3, h, w, d]\n",
    "    '''\n",
    "    this function computes the laplacian inverse of a vector field u of size 3 x size_h x size_w x size_d\n",
    "    '''\n",
    "    size_h, size_w, size_d = u.shape[-3:]\n",
    "    idty = get_idty(size_h, size_w, size_d).cpu().numpy()\n",
    "    lap = 6. - 2. * (np.cos(2. * np.pi * idty[0] / size_h) +\n",
    "                     np.cos(2. * np.pi * idty[1] / size_w) +\n",
    "                     np.cos(2. * np.pi * idty[2] / size_d))\n",
    "    lap[0, 0] = 1.\n",
    "    lapinv = 1. / lap\n",
    "    lap[0, 0] = 0.\n",
    "    lapinv[0, 0] = 1.\n",
    "\n",
    "    u = u.cpu().detach().numpy()\n",
    "    fx = np.fft.fftn(u[0])\n",
    "    fy = np.fft.fftn(u[1])\n",
    "    fz = np.fft.fftn(u[2])\n",
    "    fx *= lapinv\n",
    "    fy *= lapinv\n",
    "    fz *= lapinv\n",
    "    vx = torch.from_numpy(np.real(np.fft.ifftn(fx)))\n",
    "    vy = torch.from_numpy(np.real(np.fft.ifftn(fy)))\n",
    "    vz = torch.from_numpy(np.real(np.fft.ifftn(fz)))\n",
    "\n",
    "    return torch.stack((vx, vy, vz))#.to(device=torch.device('cuda'))\n",
    "\n",
    "        \n",
    "def metric_matching(gi, gm, height, width, depth, mask, iter_num, epsilon, sigma, dim):\n",
    "    phi_inv = get_idty(height, width, depth)\n",
    "    phi = get_idty(height, width, depth)\n",
    "    idty = get_idty(height, width, depth)\n",
    "    idty.requires_grad_()\n",
    "    f0 = torch.eye(int(dim)).repeat(height, width, depth, 1, 1)\n",
    "    f1 = torch.eye(int(dim)).repeat(height, width, depth, 1, 1)\n",
    "    \n",
    "    for j in range(iter_num):\n",
    "        phi_actsg0 = phi_pullback(phi_inv, gi)\n",
    "        phi_actsf0 = phi_pullback(phi_inv, f0)\n",
    "        E = energy_ebin(idty, phi_actsg0, gm, phi_actsf0, f1, sigma, dim, mask) \n",
    "        E.backward()\n",
    "        v = - laplace_inverse(idty.grad)\n",
    "        with torch.no_grad():\n",
    "            psi =  idty + epsilon*v  \n",
    "            psi[0][psi[0] > height - 1] = height - 1\n",
    "            psi[1][psi[1] > width - 1] = width - 1\n",
    "            psi[2][psi[2] > depth - 1] = depth - 1\n",
    "            psi[psi < 0] = 0\n",
    "            psi_inv =  idty - epsilon*v\n",
    "            psi_inv[0][psi_inv[0] > height - 1] = height - 1\n",
    "            psi_inv[1][psi_inv[1] > width - 1] = width - 1\n",
    "            psi_inv[2][psi_inv[2] > depth - 1] = depth - 1\n",
    "            psi_inv[psi_inv < 0] = 0\n",
    "            phi = compose_function(psi, phi)\n",
    "            phi_inv = compose_function(phi_inv, psi_inv)\n",
    "            idty.grad.data.zero_()\n",
    "            \n",
    "    gi = phi_pullback(phi_inv, gi)\n",
    "    return gi, phi, phi_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start from checkpoint\n",
      "start from checkpoint\n",
      "start from checkpoint\n",
      "start from checkpoint\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "file_name = [1,2,4,6]\n",
    "input_dir = '/usr/sci/projects/HCP/Kris/NSFCRCNS/TestResults/working_3d_python'\n",
    "output_dir = 'Cubic1246AtlasMay22'\n",
    "height, width, depth = 100,100,41\n",
    "sample_num = len(file_name)\n",
    "tensor_lin_list, tensor_met_list, mask_list, mask_thresh_list = [], [], [], []\n",
    "mask_union = torch.zeros(height, width, depth).double()\n",
    "phi_inv_acc_list, phi_acc_list, energy_list = [], [], []\n",
    "resume = True\n",
    "\n",
    "for s in range(len(file_name)):\n",
    "#     read tensor and mask files\n",
    "    tensor_np = sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/cubic{file_name[s]}_scaled_tensors.nhdr'))\n",
    "    mask_np = sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/cubic{file_name[s]}_filt_mask.nhdr'))\n",
    "    tensor_lin_list.append(torch.from_numpy(tensor_np).double().permute(3,2,1,0))\n",
    "#     create union of masks\n",
    "    mask_union += torch.from_numpy(mask_np).double().permute(2,1,0)\n",
    "    mask_list.append(torch.from_numpy(mask_np).double().permute(2,1,0))\n",
    "#     rearrange tensor_lin to tensor_met\n",
    "    tensor_met_zeros = torch.zeros(height,width,depth,3,3,dtype=torch.float64)\n",
    "    tensor_met_zeros[:,:,:,0,0] = tensor_lin_list[s][0]\n",
    "    tensor_met_zeros[:,:,:,0,1] = tensor_lin_list[s][1]\n",
    "    tensor_met_zeros[:,:,:,0,2] = tensor_lin_list[s][2]\n",
    "    tensor_met_zeros[:,:,:,1,0] = tensor_lin_list[s][1]\n",
    "    tensor_met_zeros[:,:,:,1,1] = tensor_lin_list[s][3]\n",
    "    tensor_met_zeros[:,:,:,1,2] = tensor_lin_list[s][4]\n",
    "    tensor_met_zeros[:,:,:,2,0] = tensor_lin_list[s][2]\n",
    "    tensor_met_zeros[:,:,:,2,1] = tensor_lin_list[s][4]\n",
    "    tensor_met_zeros[:,:,:,2,2] = tensor_lin_list[s][5]\n",
    "#     balance the background and subject by rescaling\n",
    "    tensor_met_list.append(torch.inverse(tensor_met_zeros))\n",
    "    fore_back_adaptor = torch.ones((height,width,depth))\n",
    "    mask_thresh_list.append(fore_back_adaptor)\n",
    "    tensor_met_list[s] = torch.einsum('ijk...,lijk->ijk...', tensor_met_list[s], mask_thresh_list[s].unsqueeze(0))\n",
    "#     initialize the accumulative diffeomorphism\n",
    "    if resume==False:\n",
    "        print('start from identity')\n",
    "        phi_inv_acc_list.append(get_idty(height, width, depth))\n",
    "        phi_acc_list.append(get_idty(height, width, depth))\n",
    "    else:\n",
    "        print('start from checkpoint')\n",
    "        phi_inv_acc_list.append(torch.from_numpy(sio.loadmat(f'{output_dir}/cubic{file_name[s]}_{250}_phi_inv.mat')['diffeo']))\n",
    "        phi_acc_list.append(torch.from_numpy(sio.loadmat(f'{output_dir}/cubic{file_name[s]}_{250}_phi.mat')['diffeo']))\n",
    "        tensor_met_list[s] = phi_pullback(phi_inv_acc_list[s], tensor_met_list[s])\n",
    "    \n",
    "    energy_list.append([])    \n",
    "    \n",
    "mask_union[mask_union>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c1fe03f914480590c72d125a1f9a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f38a7071550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.imshow(torch.det(tensor_met_zeros)[:,:,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from iteration 251 to iteration 1052\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "# plt.imshow(torch.det(tensor_met_list[0])[:,:,20])\n",
    "start_iter = 251\n",
    "iter_num = 801\n",
    "print(f'Starting from iteration {start_iter} to iteration {iter_num+start_iter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/801 [00:00<?, ?it/s]This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370141920/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  6%|▋         | 52/801 [37:07<9:50:53, 47.33s/it] "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(start_iter, start_iter+iter_num)):\n",
    "    G = torch.stack(tuple(tensor_met_list))\n",
    "    dim, sigma, epsilon, iter_num = 3., 0, 4e-3, 1 # epsilon = 3e-3 for orig tensor\n",
    "    atlas = get_karcher_mean(G, 1./dim)\n",
    "\n",
    "    phi_inv_list, phi_list = [], []\n",
    "    for s in range(sample_num):\n",
    "        energy_list[s].append(torch.einsum(\"ijk...,lijk->\",[(tensor_met_list[s] - atlas)**2, mask_union.unsqueeze(0)]).item())\n",
    "        old = tensor_met_list[s]\n",
    "        tensor_met_list[s], phi, phi_inv = metric_matching(tensor_met_list[s], atlas, height, width, depth, mask_union, iter_num, epsilon, sigma,dim)\n",
    "        phi_inv_list.append(phi_inv)\n",
    "        phi_list.append(phi)\n",
    "        phi_inv_acc_list[s] = compose_function(phi_inv_acc_list[s], phi_inv_list[s])\n",
    "        phi_acc_list[s] = compose_function(phi_list[s], phi_acc_list[s])\n",
    "        mask_list[s] = compose_function(mask_list[s], phi_inv_list[s])\n",
    "#         if i%50==0:\n",
    "#             plot_diffeo(phi_acc_list[s][1:, 50, :, :], step_size=2, show_axis=True)\n",
    "#             plot_diffeo(phi_acc_list[s][:2, :, :, 20], step_size=2, show_axis=True)\n",
    "#             plot_diffeo(torch.stack((phi_acc_list[s][0, :, 50, :],phi_acc_list[s][2, :, 50, :]),0), step_size=2, show_axis=True)\n",
    "            \n",
    "    '''check point'''\n",
    "    if i%50==0:\n",
    "        atlas_lin = np.zeros((6,height,width,depth))\n",
    "        mask_acc = np.zeros((height,width,depth))\n",
    "        atlas_inv = torch.inverse(atlas)\n",
    "        atlas_lin[0] = atlas_inv[:,:,:,0,0]\n",
    "        atlas_lin[1] = atlas_inv[:,:,:,0,1]\n",
    "        atlas_lin[2] = atlas_inv[:,:,:,0,2]\n",
    "        atlas_lin[3] = atlas_inv[:,:,:,1,1]\n",
    "        atlas_lin[4] = atlas_inv[:,:,:,1,2]\n",
    "        atlas_lin[5] = atlas_inv[:,:,:,2,2]\n",
    "        for s in range(sample_num):\n",
    "            sio.savemat(f'{output_dir}/cubic{file_name[s]}_{i}_phi_inv.mat', {'diffeo': phi_inv_acc_list[s].detach().numpy()})\n",
    "            sio.savemat(f'{output_dir}/cubic{file_name[s]}_{i}_phi.mat', {'diffeo': phi_acc_list[s].detach().numpy()})\n",
    "            sio.savemat(f'{output_dir}/cubic{file_name[s]}_{i}_energy.mat', {'energy': energy_list[s]})\n",
    "#             plt.plot(energy_list[s])\n",
    "            mask_acc += mask_list[s].numpy()\n",
    "        mask_acc[mask_acc>0]=1\n",
    "        sitk.WriteImage(sitk.GetImageFromArray(np.transpose(atlas_lin,(3,2,1,0))), f'{output_dir}/atlas_{i}_tens.nhdr')\n",
    "        sitk.WriteImage(sitk.GetImageFromArray(np.transpose(mask_acc,(2,1,0))), f'{output_dir}/atlas_{i}_mask.nhdr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "atlas_lin = np.zeros((6,height,width,depth))\n",
    "mask_acc = np.zeros((height,width,depth))\n",
    "\n",
    "for s in range(sample_num):\n",
    "    sio.savemat(f'{output_dir}/cubic{file_name[s]}_phi_inv.mat', {'diffeo': phi_inv_acc_list[s].detach().numpy()})\n",
    "    sio.savemat(f'{output_dir}/cubic{file_name[s]}_phi.mat', {'diffeo': phi_acc_list[s].detach().numpy()})\n",
    "    sio.savemat(f'{output_dir}/cubic{file_name[s]}_energy.mat', {'energy': energy_list[s]})\n",
    "    \n",
    "    plt.plot(energy_list[s])\n",
    "    mask_acc += mask_list[s].numpy()\n",
    "\n",
    "atlas = torch.inverse(atlas)\n",
    "atlas_lin[0] = atlas[:,:,:,0,0]\n",
    "atlas_lin[1] = atlas[:,:,:,0,1]\n",
    "atlas_lin[2] = atlas[:,:,:,0,2]\n",
    "atlas_lin[3] = atlas[:,:,:,1,1]\n",
    "atlas_lin[4] = atlas[:,:,:,1,2]\n",
    "atlas_lin[5] = atlas[:,:,:,2,2]\n",
    "mask_acc[mask_acc>0]=1\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.transpose(atlas_lin,(3,2,1,0))), f'{output_dir}/atlas_tens.nhdr')\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.transpose(mask_acc,(2,1,0))), f'{output_dir}/atlas_mask.nhdr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlas_lin = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{output_dir}/atlas_100_tens.nhdr')),(3,2,1,0))\n",
    "mask_acc = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/cubic5_filt_mask.nhdr')),(2,1,0))\n",
    "atlas_lin = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{output_dir}/atlas_750_tens.nhdr')),(3,2,1,0))\n",
    "# atlas_lin = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{output_dir}/atlas_tens.nhdr')),(3,2,1,0))\n",
    "# mask_acc = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{output_dir}/atlas_mask.nhdr')),(2,1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diffeomorphism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_3d_diffeos(diffeo, stride, interp):\n",
    "    height, width, depth = diffeo.shape[1:]\n",
    "    spline = []\n",
    "    for i in range(1,height,stride):\n",
    "        for j in range(1,width,stride):\n",
    "            spline.append(pv.Spline(np.transpose(diffeo[:,i,j,:]), interp))\n",
    "            \n",
    "    for i in range(1,height,stride):\n",
    "        for k in range(1,depth,stride):\n",
    "            spline.append(pv.Spline(np.transpose(diffeo[:,i,:,k]), interp))\n",
    "            \n",
    "    for j in range(1,width,stride):\n",
    "        for k in range(1,depth,stride):\n",
    "            spline.append(pv.Spline(np.transpose(diffeo[:,:,j,k]), interp))\n",
    "            \n",
    "    return itkview(geometries=spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984fc8f3f968495c9c37eb341076c1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diffeo = sio.loadmat(f'{output_dir}/cubic1_750_phi_inv.mat')['diffeo']\n",
    "vwr = view_3d_diffeos(diffeo, 8,1000)\n",
    "vwr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `geo.geodesicpath`'s input tensor should be original DTI tensor field, instead of the inverted one. So make sure save the DTI like result, rather than inverted atlas.\n",
    "- If you are want to visualize the path by itkview, it's recommended that **set the `both_directions` argument as `False`**. As the itkview will connect all the points in order, not like plotting the points densely in 2D case. The `geo.geodesicpath_3d` returns a concatenated list of both directions but without reversing one of them, therefore the list returned by the function is actually not in order.\n",
    "    - Likewise, setting the `geo_iters` large is better than small, as the logic in `geo.geodesicpath_3d` is like: if the expected path doesn't go beyond the mask region, the last element in the returned list would be `[0,0,0]`, which leads to a twist path after calling the `view_3d_tensors`, due to the property of `pyvista.spline`; if the expected path goes beyond the mask region, the algorithm would be forced to suspend, and the last element in the returned list wouldn't be `[0,0,0]`.\n",
    "- At `[13, 14, 21]`, the four cubics and atlas are approximately overlapped, as for the other position, this is not guaranteed.\n",
    "- When calling the `geo.geodesicpath_3d`, **make sure the mask you put in `mask_image`(second) argument aligns with the object as accurate as possible**. The `mask_union`, which covers unnecessary area, will result in the extremely slow running in `util.diff.gradient_mask_3d` and `util.maskops.determine_boundary_3d`. But in visualization, using `mask_union` is acceptable.\n",
    "- To distinguish each path, you can use the drop-down menu locates at the down-left corner of the interactive window, switch to the geometry you would like to change and choose a color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geodesic on atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_set = []\n",
    "start_coords = [[13, 14, 20]] # golden test start point\n",
    "init_velocities = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding geodesic path from [13, 14, 20] with initial velocity [0.2791895886422234, 0.9602357797194284, 0.0006487992039941156]\n",
      "Found 0 voxels where unable to take 1st derivative.\n",
      "Found 0 reduced accuracy 2nd derivative voxels.\n",
      "Finding geodesic path from [13, 14, 20] with initial velocity [-2.79189589e-01 -9.60235780e-01 -6.48799204e-04]\n",
      "Found 0 voxels where unable to take 1st derivative.\n",
      "Found 0 reduced accuracy 2nd derivative voxels.\n",
      "numpts 91\n",
      "smallest,largest max eigenvalue 1.5201600364148165 7.873303850992839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d0b365bf9b472998f2589496f23b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geo_delta_t = -0.08\n",
    "geo_iters = 1300 \n",
    "euler_delta_t = 0.1\n",
    "euler_iters = 8000 \n",
    "\n",
    "# geodesicpath_3d([6,h,w,d],[h,w,d],...)\n",
    "geox, geoy, geoz = geo.geodesicpath_3d(atlas_lin, mask_acc,\\\n",
    "                              start_coords[0], init_velocities[0], \\\n",
    "                              geo_delta_t, iter_num=geo_iters, both_directions=True)\n",
    "\n",
    "# eulerpath_3d([6,h,w,d],[h,w,d],...)\n",
    "# eulx, euly, eulz = euler.eulerpath_3d(atlas_lin, mask_acc,\\\n",
    "#                               start_coords[0], init_velocities[0], euler_delta_t, iter_num=euler_iters, both_directions=False)\n",
    "path_set = [(geox[:-1], geoy[:-1], geoz[:-1])]\n",
    "\n",
    "# view_3d_tensors([h,w,d,6],[h,w,d],...)\n",
    "# vwr=view_3d_tensors(np.transpose(atlas_lin,(1,2,3,0)),mask_acc,atlas_lin[3,:,:,:],paths=path_set,stride=6,scale=6)\n",
    "vwr=view_3d_tensors(np.transpose(atlas_lin,(1,2,3,0)),mask_acc,mask_acc,paths=path_set,stride=6,scale=6)\n",
    "vwr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geodesics on atlas and cubics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_set=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding geodesic path from [13, 14, 20] with initial velocity [0.32780079 0.94474687 0.        ]\n",
      "Found 0 voxels where unable to take 1st derivative.\n",
      "Found 0 reduced accuracy 2nd derivative voxels.\n",
      "Finding geodesic path from [13, 14, 20] with initial velocity [0.23333091 0.97239739 0.        ]\n",
      "Found 0 voxels where unable to take 1st derivative.\n",
      "Found 0 reduced accuracy 2nd derivative voxels.\n",
      "Finding geodesic path from [13, 14, 20] with initial velocity [0.27016828 0.96281312 0.        ]\n",
      "Found 0 voxels where unable to take 1st derivative.\n",
      "Found 0 reduced accuracy 2nd derivative voxels.\n",
      "Finding geodesic path from [13, 14, 20] with initial velocity [0.28914639 0.95728489 0.        ]\n",
      "Found 0 voxels where unable to take 1st derivative.\n",
      "Found 0 reduced accuracy 2nd derivative voxels.\n"
     ]
    }
   ],
   "source": [
    "geo_delta_t = 0.1\n",
    "geo_iters = 1300 \n",
    "\n",
    "for s in file_name:\n",
    "# for s in [1]:\n",
    "    tensor_lin = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/cubic{s}_scaled_tensors.nhdr')),(3,2,1,0))\n",
    "    mask = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/cubic{s}_filt_mask.nhdr')),(2,1,0))\n",
    "    geox, geoy, geoz = geo.geodesicpath_3d(tensor_lin, mask,\\\n",
    "                                            start_coords[0], init_velocities[0], \\\n",
    "                                            geo_delta_t, iter_num=geo_iters, both_directions=False)\n",
    "    path_set.append((geox[:-1],geoy[:-1],geoz[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpts 135\n",
      "smallest,largest max eigenvalue 1.0211077016528478 7.873303850992839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786f49ffbbb544e28f8580e04d3af053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[{'vtkClass': 'vtkPolyData', 'points': {'vtkClass': 'vtkPoints', 'name': '_points', 'numberO…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vwr=view_3d_tensors(np.transpose(atlas_lin,(1,2,3,0)),mask_union,atlas_lin[3,:,:,:],paths=path_set,stride=6,scale=6)\n",
    "vwr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### geodesics on cubics pushforwarded to the atlas space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def coord_register(point_x, point_y, point_z, diffeo):\n",
    "  # TODO work out which is y and which is x, maintain consistency.\n",
    "  # For now, pass in y for point_x, x for point_y\n",
    "    height, width, depth=diffeo.shape[-3:]\n",
    "    new_point_x, new_point_y, new_point_z = [], [], []\n",
    "    for i in range(len(point_x)):\n",
    "        C = point_x[i] - math.floor(point_x[i])\n",
    "        D = point_y[i] - math.floor(point_y[i])\n",
    "        E = point_z[i] - math.floor(point_z[i])\n",
    "        new_point_x.append(\\\n",
    "          (1.-C)*(1.-D)*(1.-E)*diffeo[0, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*(1.-E)*diffeo[0, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*(1.-E)*diffeo[0, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*D*(1.-E)*diffeo[0, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*(1.-D)*E*diffeo[0, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*E*diffeo[0, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*E*diffeo[0, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*D*E*diffeo[0, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth])\n",
    "\n",
    "        new_point_y.append(\\\n",
    "          (1.-C)*(1.-D)*(1.-E)*diffeo[1, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*(1.-E)*diffeo[1, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*(1.-E)*diffeo[1, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*D*(1.-E)*diffeo[1, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*(1.-D)*E*diffeo[1, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*E*diffeo[1, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*E*diffeo[1, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*D*E*diffeo[1, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth])\n",
    "\n",
    "        new_point_z.append(\\\n",
    "          (1.-C)*(1.-D)*(1.-E)*diffeo[2, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*(1.-E)*diffeo[2, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*(1.-E)*diffeo[2, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + C*D*(1.-E)*diffeo[2, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.floor(point_z[i])%depth]\\\n",
    "        + (1.-C)*(1.-D)*E*diffeo[2, math.floor(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + (1.-C)*D*E*diffeo[2, math.floor(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*(1.-D)*E*diffeo[2, math.ceil(point_x[i])%height, math.floor(point_y[i])%width, math.ceil(point_z[i])%depth]\\\n",
    "        + C*D*E*diffeo[2, math.ceil(point_x[i])%height, math.ceil(point_y[i])%width, math.ceil(point_z[i])%depth])\n",
    " \n",
    "    return (new_point_x, new_point_y, new_point_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Cubic1246AtlasMay22/cubic1_1100_phi.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/python37/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Cubic1246AtlasMay22/cubic1_1100_phi.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-55438f670a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtensor_lin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{input_dir}/cubic{s}_scaled_tensors.nhdr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{input_dir}/cubic{s}_filt_mask.nhdr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdiffeo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{output_dir}/cubic{s}_1100_phi.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diffeo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     geox, geoy, geoz = geo.geodesicpath_3d(tensor_lin, mask,\\\n\u001b[1;32m     12\u001b[0m                                             \u001b[0mstart_coords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_velocities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python37/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \"\"\"\n\u001b[1;32m    221\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python37/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python37/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python37/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Cubic1246AtlasMay22/cubic1_1100_phi.mat'"
     ]
    }
   ],
   "source": [
    "path_set = []\n",
    "start_coords = [[13, 14, 21]] # golden test start point\n",
    "init_velocities = [None]\n",
    "geo_delta_t = 0.1\n",
    "geo_iters = 1300 \n",
    "\n",
    "for s in file_name:\n",
    "    tensor_lin = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/cubic{s}_scaled_tensors.nhdr')),(3,2,1,0))\n",
    "    mask = np.transpose(sitk.GetArrayFromImage(sitk.ReadImage(f'{input_dir}/cubic{s}_filt_mask.nhdr')),(2,1,0))\n",
    "    diffeo = sio.loadmat(f'{output_dir}/cubic{s}_1100_phi.mat')['diffeo']\n",
    "    geox, geoy, geoz = geo.geodesicpath_3d(tensor_lin, mask,\\\n",
    "                                            start_coords[0], init_velocities[0], \\\n",
    "                                            geo_delta_t, iter_num=geo_iters, both_directions=False)\n",
    "    path_set.append(coord_register(geox[:-1], geoy[:-1], geoz[:-1], diffeo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwr=view_3d_tensors(np.transpose(atlas_lin,(1,2,3,0)),mask_acc,atlas_lin[3,:,:,:],paths=path_set,stride=6,scale=6)\n",
    "vwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
